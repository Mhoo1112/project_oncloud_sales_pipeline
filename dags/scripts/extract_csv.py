import os
import pandas
import datetime
from airflow.models import Variable
from google.cloud import storage
from scripts.log_start_log_end import log_start
from scripts.log_start_log_end import log_end

def extract_sales_csv():
    """
        ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå CSV ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏à‡∏≤‡∏Å‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå sales_files/
        - ‡∏£‡∏ß‡∏°‡πÄ‡∏õ‡πá‡∏ô DataFrame ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
        - ‡∏õ‡∏£‡∏±‡∏ö‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô
        - ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤ DataFrame
        """
    log_start()
    # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å Variable
    bucket_name = Variable.get("GCP_BUCKET_NAME")
    # ‡∏Ñ‡πà‡∏≤‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏≠‡∏∑‡πà‡∏ô‡πÜ
    today = datetime.date.today().strftime("%Y-%m-%d")
    prefix = "raw_data/" # ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πá‡∏ö raw data
    tmp_path = "/tmp" # ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß‡∏ö‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏£‡∏±‡∏ô
    output_path = "output/"

    # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Google client
    client = storage.Client()
    bucket = client.bucket(bucket_name)
    blobs = client.list_blobs(bucket, prefix=prefix) # bucket_name/raw_data/

    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏•‡∏¥‡∏™‡∏ï‡πå‡πÑ‡∏ß‡πâ‡∏£‡∏ß‡∏°‡∏ó‡∏∏‡∏Å DataFrame
    all_files = []

    # for filename in os.listdir(folder_path):
    for blob in blobs: # client.list_blobs(bucket, prefix=prefix):
        blob_name = blob.name.split("/")[-1]
        # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå CSV
        if blob_name.startswith("2024_sales") and blob_name.endswith(".csv"):
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß ‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡∏•‡∏ö‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏£‡∏±‡∏ô‡πÄ‡∏™‡∏£‡πá‡∏à
            local_tmp = os.path.join(tmp_path, blob_name) # /tmp/2024_sales_01.csv
            # ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏à‡∏≤‡∏Å GCS ‡πÑ‡∏ß‡πâ‡∏ó‡∏µ‡πà local tmp ‡∏Å‡πà‡∏≠‡∏ô‡∏≠‡πà‡∏≤‡∏ô‡∏î‡πâ‡∏ß‡∏¢ pandas
            blob.download_to_filename(local_tmp)
            print(f"‚¨áÔ∏è Downloaded: gs://{bucket_name}/{blob.name} -> {local_tmp}")
            
            try:
                # ‡∏≠‡πà‡∏≤‡∏ô CSV
                data_frame = pandas.read_csv(local_tmp)
                print("\n‚ñ∂Ô∏è local_tmp")
                print(local_tmp)

                # ‡πÅ‡∏õ‡∏•‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå
                new_columns = []
                for col in data_frame.columns:
                    col = col.strip()
                    col = col.replace(' ', '_')
                    col = col.lower()
                    new_columns.append(col)
                # print("\n‚ñ∂Ô∏ènew_columns")
                # print(new_columns)
                data_frame.columns = new_columns
                # ‡πÅ‡∏õ‡∏•‡∏á‡∏ä‡∏∑‡πà‡∏≠ column
                data_frame = data_frame.rename(
                    columns={
                        "orderid": "order_id",
                        "orderdate": "order_date",

                    }
                )
                # ‡πÄ‡∏£‡∏µ‡∏¢‡∏á column
                # data_frame = data_frame[sorted(data_frame.columns)] ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏à‡∏≤‡∏Å‡∏ô‡πâ‡∏≠‡∏¢‡πÑ‡∏õ‡∏°‡∏≤‡∏Å
                required_cols = ['order_id', 'order_date', 'customer_id', 'product_id', 'amount_usd']
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏Ç‡∏≤‡∏î
                ordered_cols = []
                # ‡∏ß‡∏ô‡∏•‡∏π‡∏õ‡πÄ‡∏≠‡∏≤‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ï‡∏≤‡∏°‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
                for col in required_cols:
                    if col in data_frame.columns:
                        ordered_cols.append(col)
                # ‡∏ß‡∏ô‡∏•‡∏π‡∏õ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏≠‡∏∑‡πà‡∏ô ‡πÜ ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏∑‡∏≠
                for col in data_frame.columns:
                    if col not in required_cols:
                        ordered_cols.append(col)
                # ‡πÄ‡∏£‡∏µ‡∏¢‡∏á column ‡∏ï‡∏≤‡∏° ordered_cols
                data_frame = data_frame[ordered_cols]

                # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå
                data_frame["order_date"] = pandas.to_datetime(data_frame["order_date"], errors="coerce")
                data_frame["order_date"] = pandas.to_datetime(data_frame["order_date"].dt.strftime("%Y-%m-%d"),
                                                              errors="coerce")
                data_frame["amount_usd"] = pandas.to_numeric(data_frame["amount_usd"], errors="coerce")
                # data_frame["amount_usd"] = data_frame["amount_usd"].fillna(0)

                print("\n‚ñ∂Ô∏è DataFrame of each file")
                print(data_frame)
                print(f"‚úÖ Loaded: {blob_name} | {len(data_frame)} rows x {len(data_frame.columns)} cols")

                if not data_frame.empty:
                    all_files.append(data_frame)
                else:
                    print(f"! Empty file: {blob_name}")
            except Exception as e:
                print(f"‚ùå Error loading file {blob_name}: {e}")
                continue
    # ‡∏£‡∏ß‡∏°‡∏ó‡∏∏‡∏Å DataFrame
    if all_files:
        combined_df = pandas.concat(all_files, ignore_index=True)
        combined_df = combined_df.drop_duplicates().reset_index(drop=True)
        # combined_df = combined_df.dropna(subset=["customer_id"])
        combined_df = combined_df.dropna().reset_index(drop=True)
        print("\n Ô∏è‚úÖ dtypes")
        print(combined_df.dtypes)
        print("\n Ô∏è‚úÖ count")
        print(combined_df.count())
        print("\n Ô∏è‚úÖ DataFrame Combined --------------------")
        print(combined_df)

        # ‡πÄ‡∏ã‡∏ü‡πÑ‡∏ü‡∏•‡πå‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÑ‡∏ß‡πâ‡πÉ‡∏ô /tmp
        out_csv_local = os.path.join(tmp_path, "cleaned_sales.csv")
        out_parq_local = os.path.join(tmp_path, "cleaned_sales.parquet")


        combined_df.to_csv(out_csv_local, index=False)
        combined_df.to_parquet(out_parq_local)


        print(f"üíæ Saved: {out_csv_local}")
        print(f"üíæ Saved: {out_parq_local}")

        bucket.blob(os.path.join(output_path, f"cleaned_sales_{today}.csv")).upload_from_filename(out_csv_local)
        bucket.blob(os.path.join(output_path, f"cleaned_sales_{today}.parquet")).upload_from_filename(out_parq_local)

    else:
        combined_df = pandas.DataFrame()  # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏•‡∏¢
        print("\n‚úÖ DataFrame --------------------")
        print(combined_df)

    log_end()
    return combined_df