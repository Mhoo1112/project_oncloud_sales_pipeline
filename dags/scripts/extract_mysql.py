import os
import pandas
import sqlalchemy
from airflow.models import Variable
from airflow.hooks.base import BaseHook
from google.cloud import storage
import datetime
from scripts.log_start_log_end import log_start
from scripts.log_start_log_end import log_end


def extract_mysql():
    """
    ‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å MySQL ‡∏ä‡∏∑‡πà‡∏≠ Data Base: project_sales_pipeline/
    """
    log_start()

    # ‡∏Ñ‡πà‡∏≤‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏≠‡∏∑‡πà‡∏ô‡πÜ
    tmp_path = f"/tmp"
    output_path = f"output/"

    # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å Variable
    bucket_name = Variable.get("GCP_BUCKET_NAME")

    # host = Variable.get("MYSQL_HOST")
    # port = Variable.get("MYSQL_PORT")
    # database = Variable.get("MYSQL_DATABASE")
    # username = Variable.get("MYSQL_USER")
    # password = Variable.get("MYSQL_PASSWORD")

    # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Google client
    client = storage.Client()
    bucket = client.get_bucket(bucket_name)

    # ‡∏™‡∏£‡πâ‡∏≤‡∏á connection string
    # engine = sqlalchemy.create_engine(
    #     f"mysql+pymysql://{username}:{password}@{host}:{port}/{database}")

    # ‡∏™‡∏£‡πâ‡∏≤‡∏á connection string
    # ‡πÄ‡∏û‡∏¥‡πà‡∏° connect_timeout ‡πÅ‡∏•‡∏∞ read_timeout ‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÉ‡∏ô Connection string
    # ‡∏î‡∏∂‡∏á‡∏Ñ‡πà‡∏≤‡∏à‡∏≤‡∏Å Admin > Connections (conn_id = mysql_cloudsql)
    
    conn = BaseHook.get_connection("mysql_cloudsql")
    url = f"mysql+pymysql://{conn.login}:{conn.password}@{conn.host}:{conn.port}/{conn.schema}"
    engine = sqlalchemy.create_engine(
        url + "?connect_timeout=10&read_timeout=30",
        pool_pre_ping=True,
        pool_recycle=3600,
    )

    query_df = pandas.read_sql("""
    SELECT
        CONCAT('C', LPAD(c.customer_id, 3, '0')) AS customer_id,   -- ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô C001
        c.customer_name,
        c.customer_email,
        p.product_id,
        p.product_name,
        p.price
        FROM customers c
        JOIN products p ON c.customer_id = p.customer_id;
        """, engine)

    query_df["extracted_date"] = pandas.Timestamp.now().strftime("%Y-%m-%d")
    print("\n‚ñ∂Ô∏è DataFrame from MySQL --------------------")
    print(query_df.head())
    print("\n‚ñ∂Ô∏è Describe from MySQL")
    print(query_df.describe())
    print("\n‚ñ∂Ô∏è Dtypes from MySQL")
    print(query_df.dtypes)

    try:
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ü‡∏•‡πå CSV ‡πÅ‡∏•‡∏∞ parquet
        today = datetime.date.today().strftime("%Y-%m-%d")
        out_csv_local = os.path.join(tmp_path, f"mysql_customers_products_{today}.csv")
        out_parq_local = os.path.join(tmp_path, f"mysql_customers_products_{today}.parquet")

        query_df.to_csv(out_csv_local, index=False)
        query_df.to_parquet(out_parq_local)

        print(f"üíæ Saved: {out_csv_local}")
        print(f"üíæ Saved: {out_parq_local}")

        # ‡∏≠‡∏±‡∏û‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏õ‡πÑ‡∏ü‡∏•‡πå‡∏õ‡∏•‡∏≤‡∏¢‡∏ó‡∏≤‡∏á ‡∏ä‡∏∑‡πà‡∏≠ mysql_customers_ ... ‡∏à‡∏≤‡∏Å /tpm ‡∏ä‡∏∑‡πà‡∏≠ mysql_customers_ ... 
        bucket.blob(os.path.join(
            output_path, f"mysql_customers_products_{today}.csv")).upload_from_filename(out_csv_local)
        bucket.blob(os.path.join(
            output_path, f"mysql_customers_products_{today}.parquet")).upload_from_filename(out_parq_local)

    except Exception as e:
        print(e)

    engine.dispose()
    log_end()
    return query_df
